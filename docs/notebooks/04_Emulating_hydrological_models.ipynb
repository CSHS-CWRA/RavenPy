{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Emulating hydrological models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Ravenpy to emulate an existing hydrological model\n",
    "\n",
    "In this notebook, we will demonstrate the versatility of the Raven modelling framework to emulate one of eight hydrological models that are currently supported. We will walk through the different configuration parameters required to build the model and simulate streamflow on a catchments. We will also show how to import files from a pre-configured Raven configuration that users can inport into Ravenpy instead of using one of the default emulators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on datasets\n",
    "\n",
    "There are numerous ways to run a Raven model and to pass its required input data. For this introduction to RavenPy, we will use our ERA5 data we generated in the previous notebook and we will configure the Raven model instance on the fly! In the next tutorials, we will see how users can import and use their own datasets to make the entire process flexible and tailored the user needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using templated model emulators\n",
    "The first thing we need to run the raven model is... a Raven model! Raven is not a model per se, but a modelling framework that can be used to build hydrological models from their underlying components. For now, PAVICS-Hydro allows building a set of pre-determined models. The Python wrapper offers at present eight model emulators: GR4J-CN, HMETS, MOHYSE, HBV-EC, Canadian Shield, HYPR, Sacramento and Blended. For each of these, templated configuration files are available to facilitate launching the model with options passed by Python at run-time. \n",
    "\n",
    "In the next cell, we are going to import the possible models, and later, we will configure and run the GR4J-CN model. Please see the documentation for more details on the mandatory vs optional parameters, and what they represent. A small glimpse is provided here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the list of possible model templates.\n",
    "from ravenpy.new_config.emulators import (\n",
    "    GR4JCN,\n",
    "    HBVEC,\n",
    "    HMETS,\n",
    "    HYPR,\n",
    "    SACSMA,\n",
    "    blended,\n",
    "    canadianshield,\n",
    "    mohyse,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step, we will define the hydrological response unit (HRU). For lumped models, there is only one unit so the following structure should be good. However, for distributed modelling, there will be more than one HRU, so we would use another tool to help us build the HRUs in that case. The HRU provides information on the area, elevation, and location of the catchment. \n",
    "\n",
    "For now, let's provide the basin properties such that Raven can run. These are the minimal values that must always be provided, but some models might require other inputs. Please see the Raven documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hydrological response unit. We can use the information from the tutorial notebook #02! Here we are using\n",
    "# arbitrary data for a test catchment.\n",
    "hru = {}\n",
    "hru = dict(\n",
    "    area=4250.6,\n",
    "    elevation=843.0,\n",
    "    latitude=54.4848,\n",
    "    longitude=-123.3659,\n",
    "    hru_type=\"land\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next required inputs are the start and end dates for the simulation. The `start_date` and `end_date` arguments indicate when a simulation should start and end. As long as the forcing data covers the simulation period, it should work. If these parameters are not defined, then start and end dates default to the start and end of the driving data. \n",
    "\n",
    "To keep things simple, we will use a short 5-year period. Note that the dates are python datetime.datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "start_date = dt.datetime(1985, 1, 1)\n",
    "end_date = dt.datetime(1990, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to build our first Raven-based hydrological model. the model will be the GR4JCN model. The following code block will show and describe every step. However, more control options are available for users. Please see the documentation for a more detailed explanation on model options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rvi': PosixPath('/home/ets/src/run_results_NB4/test.rvi'),\n",
       " 'rvp': PosixPath('/home/ets/src/run_results_NB4/test.rvp'),\n",
       " 'rvc': PosixPath('/home/ets/src/run_results_NB4/test.rvc'),\n",
       " 'rvh': PosixPath('/home/ets/src/run_results_NB4/test.rvh'),\n",
       " 'rvt': PosixPath('/home/ets/src/run_results_NB4/test.rvt')}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "from ravenpy.new_config import commands as rc\n",
    "\n",
    "# Import required packages. We already imported the GR4JCN emulator in the first cell, but let's keep it here for\n",
    "# completeness.\n",
    "from ravenpy.new_config.emulators import GR4JCN\n",
    "\n",
    "# Alternative variable names are useful for allowing Raven to read variables from NetCDF files even if the variable\n",
    "# names are not those that are expected by Raven. For example, our ERA5-dernived temperature variables are named\n",
    "# \"tmax\" and \"tmin\", whereas Raven expects \"TEMP_MAX\" and \"TEMP_MIN\". Therefore, instead of forcing users to rename\n",
    "# their variables, we provide a mechanism to tell Raven which variables in the NetCDF files correspond to which\n",
    "# meteorological variable.\n",
    "alt_names = {\n",
    "    \"TEMP_MIN\": \"tmin\",\n",
    "    \"TEMP_MAX\": \"tmax\",\n",
    "    \"PRECIP\": \"pr\",\n",
    "}\n",
    "\n",
    "# Here is where we build the raven configuration. We will first configure the model in memory based on the user\n",
    "# preferences, and then we will write the Raven configuration files to disk such that Raven can read them and\n",
    "# execute a simulation. In this case, we are building a GR4JCN model, but you could change this to any of the\n",
    "# eight models that are preconfigured for direct emulation in Ravenpy.\n",
    "\n",
    "m = GR4JCN(\n",
    "    # Raven requires parameters for the GR4JCN model. For now, we provide default values, but in a later notebook\n",
    "    # we will show how to calibrate and find new parameters for our model.\n",
    "    params=[0.529, -3.396, 407.29, 1.072, 16.9, 0.947],\n",
    "    # Here we will prepare the weather gauge data to be fed to the model. The data could also come from other\n",
    "    # sources such as the ERA5 reanalysis product. There are 2 ways to do this. We will show one way here, and\n",
    "    # then show the alternative method in the following cell.\n",
    "    #\n",
    "    # METHOD 1: If you have one netcdf file of data per meteorological variable (such as what is generated in the\n",
    "    #    03_Extracting_forcing_data.ipynb notebook), you can add them successively as follows. Note that we are\n",
    "    #    creating a gauge for each variable. Raven will use the data from the three sources to provide forcing\n",
    "    #    data to the simulation.\n",
    "    #\n",
    "    #   You can add the files you need! As long as there are timestamps associated with each value in the netcdf\n",
    "    #   files, and the other required information (data_type, alt_names, other required information), the code\n",
    "    #   will accept them and use what it needs. As per the Raven model itself, the gauge station elevation, latitude\n",
    "    #   and longitude are required to let the model run. For lumped models such as the ones we are currently\n",
    "    #   emulating, there is only one \"station\" that corresponds to the basin-averaged weahter. In this case, we\n",
    "    #   set the station elevation to that of the mean catchment elevation to remove any adiabatic gradient\n",
    "    #   modifications to the data. We also provide the catchment centroid latitude and longitude which we take\n",
    "    #   from the only HRU defining the entire catchment. For multi-gauge basins and semi-distributed models, the\n",
    "    #   latitude and longitude must be correctly identified for each station.\n",
    "    Gauge=rc.Gauge.from_nc(\n",
    "        \"ERA5_tmax.nc\",  # This file is the ERA5-derived maximum daily temperature.\n",
    "        data_type=[\n",
    "            \"TEMP_MAX\"\n",
    "        ],  # Raven expects maximum temperature to be identified as \"TEMP_MAX\", so we indicate that this variable is maximum temperature.\n",
    "        alt_names=alt_names,  # However, the variable name in the\n",
    "        extra={\n",
    "            1: {\n",
    "                \"elevation\": hru[\"elevation\"],\n",
    "                \"latitude\": hru[\"latitude\"],\n",
    "                \"longitude\": hru[\"longitude\"],\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    + rc.Gauge.from_nc(\n",
    "        \"ERA5_tmin.nc\",\n",
    "        data_type=[\"TEMP_MIN\"],\n",
    "        alt_names=alt_names,\n",
    "        extra={\n",
    "            1: {\n",
    "                \"elevation\": hru[\"elevation\"],\n",
    "                \"latitude\": hru[\"latitude\"],\n",
    "                \"longitude\": hru[\"longitude\"],\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    + rc.Gauge.from_nc(\n",
    "        \"ERA5_pr.nc\",\n",
    "        data_type=[\"PRECIP\"],\n",
    "        alt_names=alt_names,\n",
    "        extra={\n",
    "            1: {\n",
    "                \"elevation\": hru[\"elevation\"],\n",
    "                \"latitude\": hru[\"latitude\"],\n",
    "                \"longitude\": hru[\"longitude\"],\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    # The HRU as defined earlier must be provided. This is the physical representation of the catchment that Raven\n",
    "    # needs for certain models and processes.\n",
    "    HRUs=[hru],\n",
    "    # Model simulation start and end dates.\n",
    "    StartDate=start_date,\n",
    "    EndDate=end_date,\n",
    "    # Name of the simulation. Raven will prefix all .rvX files and model outputs with the runName.\n",
    "    RunName=\"test\",\n",
    "    # Custom outputs allow pre-processing of certain statistics and variables after the model runs. Please see the\n",
    "    # documentation for more details on possible options.\n",
    "    CustomOutput=rc.CustomOutput(\"YEARLY\", \"AVERAGE\", \"PRECIP\", \"ENTIRE_WATERSHED\"),\n",
    "    # GR4JCN needs an extra constant parameter for the catchment, corresponding to the G50 parameter in the CEMANEIGE\n",
    "    # description. Here is how we provide it.\n",
    "    GlobalParameter={\"AVG_ANNUAL_RUNOFF\": 208.480},\n",
    ")\n",
    "\n",
    "# We are now ready to write this newly-configured model to disk through the use of .rvX files that Raven will read.\n",
    "\n",
    "# In the following code snippet, there is a \"workdir\" path that must be provided. This indicates the path\n",
    "# where the data used to run the model (RAVEN .RV files) will be made available from the PAVICS Jupyter environment.\n",
    "# The default \"workdir\" setting puts model outputs in the temporary directory (\"/tmp\"),\n",
    "# which is not visible from the Jupyter file explorer. Therefore, You can change the last subfolder,\n",
    "# but '/notebook_dir/writable-workspace/' must be the beginning  of the path when running on the PAVICS platform.\n",
    "\n",
    "# Value for server, to change\n",
    "# m = write_rv(workdir=\"/notebook_dir/writable-workspace/run_results_NB4\", overwrite = True)\n",
    "m.write_rv(workdir=\"/home/ets/src/run_results_NB4\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rvi': PosixPath('/home/ets/src/run_results_NB4/test.rvi'),\n",
       " 'rvp': PosixPath('/home/ets/src/run_results_NB4/test.rvp'),\n",
       " 'rvc': PosixPath('/home/ets/src/run_results_NB4/test.rvc'),\n",
       " 'rvh': PosixPath('/home/ets/src/run_results_NB4/test.rvh'),\n",
       " 'rvt': PosixPath('/home/ets/src/run_results_NB4/test.rvt')}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2- Alternatively, we could already have (or we could create) a single netcdf file containing all the required\n",
    "#    forcing data. Let's see what that could look like. Note that some variables that were defined in the previous\n",
    "#    cell are reused here!\n",
    "\n",
    "#    Since our meteorological gauge data is all included in a single file, we need to tell the model which variables\n",
    "#    we are providing. We will generate the list now and pass it later to Ravenpy as an argument to the model.\n",
    "data_type = [\"TEMP_MAX\", \"TEMP_MIN\", \"PRECIP\"]\n",
    "\n",
    "#    In this second case, we want to use a single forcing data file instead of separate files for each of the\n",
    "#    weather data variables. Let's combine them into a single file:\n",
    "ds1 = xr.open_dataset(\"ERA5_tmax.nc\")\n",
    "ds2 = xr.open_dataset(\"ERA5_tmin.nc\")\n",
    "ds3 = xr.open_dataset(\"ERA5_pr.nc\")\n",
    "ds4 = xr.merge([ds1, ds2, ds3])\n",
    "ds4.to_netcdf(\"ERA5_weather_data.nc\")\n",
    "\n",
    "#    Now that we have the single file containing tmax, tmin and pr, we can setup a single gauge that contains all three.\n",
    "m = GR4JCN(\n",
    "    params=[0.529, -3.396, 407.29, 1.072, 16.9, 0.947],\n",
    "    # Setup the gauge using the second method, i.e., using a single file that contains all meteorological inputs. As\n",
    "    # you can see, a single gauge is added, but it contains all the information we need.\n",
    "    Gauge=rc.Gauge.from_nc(\n",
    "        \"ERA5_weather_data.nc\",\n",
    "        data_type=data_type,  # Note that this is the list of all the variables\n",
    "        alt_names=alt_names,  # Note that all variables here are mapped to their names in the netcdf file.\n",
    "        extra={\n",
    "            1: {\n",
    "                \"elevation\": hru[\"elevation\"],\n",
    "                \"latitude\": hru[\"latitude\"],\n",
    "                \"longitude\": hru[\"longitude\"],\n",
    "            }\n",
    "        },\n",
    "    ),\n",
    "    HRUs=[hru],\n",
    "    StartDate=start_date,\n",
    "    EndDate=end_date,\n",
    "    RunName=\"test\",\n",
    "    CustomOutput=rc.CustomOutput(\"YEARLY\", \"AVERAGE\", \"PRECIP\", \"ENTIRE_WATERSHED\"),\n",
    "    GlobalParameter={\"AVG_ANNUAL_RUNOFF\": 208.480},\n",
    ")\n",
    "\n",
    "# Value for server, to change\n",
    "# m = write_rv(workdir=\"/notebook_dir/writable-workspace/run_results_NB4\", overwrite = True)\n",
    "m.write_rv(workdir=\"/home/ets/src/run_results_NB4\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that both methods generated .rvX files in the indicated path. This makes the Ravenpy platform more flexible for various use-cases, where some data can be stored in independent files or databases (perhaps temperatures come from one source and precipitation from another source).\n",
    "\n",
    "The above code only created the .rvX files. The model did not actually run yet. To do so, we must ask it to, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we already have a model configuration that we built in-memory (such as the \"m\" GR4JCN model we built above),\n",
    "# then we can use the Emulator object to simply emulate the model we were working on.\n",
    "from ravenpy import Emulator\n",
    "\n",
    "m = Emulator(config=m, workdir=\"/home/ets/src/run_results_NB4_Emulator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the above demonstration shows how to use one of the eight emulators to run a Raven simulation. Ravenpy also contains other powerful tools to run other user-defined raven models by reading existing configuration files and running the model in Ravenpy. This means that users that already have Raven models of their systems can upload the configuration and hydrometeorological data netcdf files to their private account on the PAVICS-Hydro server and run their model there. Here is an example of how this could be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ets/src/RavenPy/ravenpy/ravenpy.py:239: RavenWarning: The required parameter RAIN_ICEPT_PCT for vegetation class VEG_ALL was autogenerated with value 0.120000\n",
      "  warn(msg, category=RavenWarning)\n",
      "/home/ets/src/RavenPy/ravenpy/ravenpy.py:239: RavenWarning: The required parameter SNOW_ICEPT_PCT for vegetation class VEG_ALL was autogenerated with value 0.100000\n",
      "  warn(msg, category=RavenWarning)\n",
      "/home/ets/src/RavenPy/ravenpy/ravenpy.py:239: RavenWarning: The required parameter RAIN_ICEPT_PCT for vegetation class VEG_WATER was autogenerated with value 0.120000\n",
      "  warn(msg, category=RavenWarning)\n",
      "/home/ets/src/RavenPy/ravenpy/ravenpy.py:239: RavenWarning: The required parameter SNOW_ICEPT_PCT for vegetation class VEG_WATER was autogenerated with value 0.100000\n",
      "  warn(msg, category=RavenWarning)\n",
      "/home/ets/src/RavenPy/ravenpy/ravenpy.py:239: RavenWarning: Because no processes with CANOPY_SNOW variable have been specified, all snow interception will be directly moved to the atmosphere as if it had sublimated.\n",
      "  warn(msg, category=RavenWarning)\n",
      "/home/ets/src/RavenPy/ravenpy/ravenpy.py:239: RavenWarning: Because no processes with CANOPY variable have been specified, all rain interception will be directly moved to the atmosphere as if it had evaporated.\n",
      "  warn(msg, category=RavenWarning)\n"
     ]
    }
   ],
   "source": [
    "# If we want to import our own raven configuration files and forcing data, we can do so by importing them\n",
    "# using the ravenpy.run  method. This will run the model exactly as the users will have designed it.\n",
    "from ravenpy.ravenpy import run\n",
    "\n",
    "run_name = \"test\"  # This is used to specify the raven configuration files prefixes. In this case, files are named test.rvi, test.rvc, etc.\n",
    "configdir = \"/home/ets/src/run_results_NB4\"  # This is the path where the files were uploaded by the user. Model outputs will also be placed there in a subfolder called \"outputs\"\n",
    "m = run(run_name=run_name, configdir=\"/home/ets/src/run_results_NB4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has run, we want to see the outputs. Ravenpy provides a tool to import and read simulation results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ravenpy.ravenpy.OutputReader at 0x7f3d361b20e0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ravenpy import OutputReader\n",
    "\n",
    "OutputReader(run_name=\"test\", path=\"/home/ets/src/run_results_NB4_Emulator/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are as follow:\n",
    "\n",
    "- hydrograph: The actual simulated hydrograph (q_sim), in netcdf format. It also contains the observed discharge (q_obs) if observed streamflow was provided as a forcing file.\n",
    "- storage: The state variables of the simulation duration, in netcdf format\n",
    "- solution: The state variables at the end of the simulation, which are saved as a \".rvc\" file that can be used to hot-start a model (for forecasting, for example)\n",
    "- rv_config: The model and data files packaged into a zip file that can be downloaded to run this exact model setup elsewhere on PAVICS-Hydro or on your local machine.\n",
    "\n",
    "You can explore the outputs using one of the following two syntaxes. One provides a path to the data, one actually loads the data into memory to be used directly in another cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This syntax will allow you to get the path to where the output files are located on the server.\n",
    "print(model.outputs[\"hydrograph\"])\n",
    "print(model.outputs[\"storage\"])\n",
    "print(model.outputs[\"solution\"])\n",
    "print(model.outputs[\"rv_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model outputs are actually already loaded as Python objects in memory, thus we can access the data directly.\n",
    "# Note that there is no way to work with the zip-file directly, so only the objects that contain useful data can be read-in this way:\n",
    "print(\"----------------HYDROGRAPH----------------\")\n",
    "print(model.hydrograph)\n",
    "print(\"\")\n",
    "print(\"-----------------STORAGE------------------\")\n",
    "print(model.storage)\n",
    "print(\"\")\n",
    "print(\"-----------------SOLUTION-----------------\")\n",
    "print(model.solution)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model has generated a simulation using the forcing data we provided, but it only used the period between the start_date and end_date. We can confirm this by looking at the forcing data. Since we have 3 forcing data files, we will want to open them using the 'open_mfdataset' method in xarray:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "dataset = xr.open_mfdataset(forcing)\n",
    "print(dataset)\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dates cover the period 1980-01-01 to 1991-01-01. In our simulation, we only ask to run over the period from 1985-01-01 to 1991-01-01. Raven takes care of subsetting the data for the required period. We can look at the simulated streamflow from Raven to confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the graphing utility built to handle Raven model outputs\n",
    "from ravenpy.utilities.nb_graphs import hydrographs\n",
    "\n",
    "hydrograph_objects = model.hydrograph\n",
    "hydrographs(hydrograph_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the simulated flow covers only the period we asked for. The results probably don't look good, but that's OK! We will soon calibrate our model to get reasonable parameters.\n",
    "\n",
    "We could also simply do basic plots using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hydrograph.q_sim.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can inspect and work with other state variables in the model outputs. For example, say we want to investigate the snow water equivalent timeseries. We can first get the list of available state variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.storage.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then plot the variable of interest:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the \"Snow\" variable\n",
    "model.storage[\"Snow\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, PAVICS-Hydro makes it easy to build a hydrological model, run it with forcing data, and then interact with the results! In the next notebooks, we will see how to use model configuration files (the .rvX files) to setup and run a model, and also how to calibrate its parameters. \n",
    "\n",
    "\n",
    "\n",
    "## Supplementary information on Hydrological response unit definition\n",
    "Raven requires a description of the watershed streamflow is simulated in. Different models require different parameters, but minimally, area, elevation, latitude and longitude are required. These data need to be provided for a few reasons:\n",
    "* Area is required since the size of the watershed will directly influence the simulated streamflow. Units are in square kilometers (km²).\n",
    "* Elevation (average elevation of the watershed) is required, although in many models the value is not actually used and therefore can be set to an arbitrary number. We strongly recommend using the real elevation as that will ensure that the value is present if you decide to switch to another model that requires elevation. Elevation is expressed in meters above mean sea level.\n",
    "* Latitude and longitude refer to the catchment centroid, and are used, among others, for evapotranspiration  computations. They are expressed in decimal degrees (°), with longitudes within [-180, 180].\n",
    "\n",
    "These values should be either precomputed externally, or they can be computed using the PAVICS-Hydro geophysical extraction toolbox that we used in the second tutorial notebook.\n",
    "\n",
    "## Supplementary information on model parameters\n",
    "\n",
    "Each model requires a set of tuning parameters to represent and compensate for unknown quantities in certain hydrological processes. Some models have more parameters than others, for example:\n",
    "\n",
    "* GR4JCN = 6 parameters\n",
    "* HMETS = 21 parameters\n",
    "* MOHYSE = 10 parameters\n",
    "* HBVEC = 21 parameters\n",
    "\n",
    "These parameters are found through calibration by tuning their values until the simulated streamflow matches the observations as much as possible. PAVICS-Hydro provides an integrated calibration toolbox that will be explored in the the 6th step of this tutorial. For now, we simply provided a set of parameters but it is not yet fully calibrated. This explains the poor quality of the simulated hydrograph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore!\n",
    "With this information in mind, you can now explore running different models and parameters and on different periods, and display the simulated hydrographs. You can change the start and end dates, the area, latitude, and even add other options that you might find in the documentation or in later tutorials.\n",
    "\n",
    "If you want to run other models than GR4JCN, you can use these parameter sets:\n",
    "\n",
    "#### HMETS: \n",
    "params = (9.5019, 0.2774, 6.3942, 0.6884, 1.2875, 5.4134, 2.3641, 0.0973, 0.0464, 0.1998, 0.0222, -1.0919, 2.6851, 0.3740, \n",
    "          1.0000, 0.4739, 0.0114, 0.0243, 0.0069, 310.7211, 916.1947)\n",
    "       \n",
    "#### MOHYSE:\n",
    "params = (1.0, 0.0468, 4.2952, 2.658, 0.4038, 0.0621, 0.0273, 0.0453, 0.9039, 5.6167)\n",
    "\n",
    "#### HBVEC:\n",
    "params = (0.059845, 4.07223, 2.00157, 0.034737, 0.09985, 0.506, 3.4385, 38.32455, 0.46066, 0.06304, 2.2778, 4.8737,\n",
    "          0.5718813, 0.04505643, 0.877607, 18.94145, 2.036937, 0.4452843, 0.6771759, 1.141608, 1.024278)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
