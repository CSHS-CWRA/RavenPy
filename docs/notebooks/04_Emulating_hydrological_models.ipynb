{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Emulating hydrological models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Raven to emulate an existing hydrological model\n",
    "\n",
    "In this notebook, we will demonstrate the versatility of the Raven modelling framework to emulate one of eight hydrological models that are currently supported. We will walk through the different configuration parameters required to build the model and simulate streamflow on a catchment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on datasets\n",
    "\n",
    "There are numerous ways to run a Raven model and to pass its required input data. For this introduction to RavenPy, we will use our ERA5 data we generated in the previous notebook and we will configure the Raven model instance on the fly! In the next tutorials, we will see how users can import and use their own datasets to make the entire process flexible and tailored the user needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using templated model emulators\n",
    "The first thing we need to run the raven model is... a Raven model! Raven is not a model per se, but a modelling framework that can be used to build hydrological models from their underlying components. For now, PAVICS-Hydro allows building a set of pre-determined models. The Python wrapper offers at present eight model emulators: GR4J-CN, HMETS, MOHYSE, HBV-EC, Canadian Shield, HYPR, Sacramento and Blended. For each of these, templated configuration files are available to facilitate launching the model with options passed by Python at run-time. \n",
    "\n",
    "In the next cell, we are going to configure and run the GR4J-CN model. Please see the documentation for more details on the mandatory vs optional parameters, and what they represent. A small glimpse is provided here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the list of possible model templates.\n",
    "from ravenpy.models import (\n",
    "    BLENDED,\n",
    "    CANADIANSHIELD,\n",
    "    GR4JCN,\n",
    "    HBVEC,\n",
    "    HMETS,\n",
    "    HYPR,\n",
    "    MOHYSE,\n",
    "    SACSMA,\n",
    ")\n",
    "\n",
    "# Generate a GR4JCN-configured Raven model instance.\n",
    "# By replacing \"GR4JCN()\" by \"HMETS()\", we would then be running a HMETS model emulator instead.\n",
    "# Also, by adding the \"workdir\" path, the data used to run the model (RAVEN .RV files) will be made available\n",
    "# from the PAVICS Jupyter environment. The default\"workdir\" setting puts model outputs in the temporary (\"/tmp\"), which\n",
    "# is not visible from the Jupyter file explorer. Therefore, You can change the last subfolder,\n",
    "# but '/notebook_dir/writable-workspace/' must be the beginning  of the path when running on the PAVICS platform.\n",
    "\n",
    "#    model = GR4JCN(workdir=\"/notebook_dir/writable-workspace/run_results\") #Value for server, to change\n",
    "model = GR4JCN(workdir=\"/home/ets/src/run_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GR4JCN model has now been created, and is ready to be parameterized. In a nutshell, when the Raven executable is launched, it will look for configuration files and use those to run the desired model components to generate streamflow. This is done behind the scenes in PAVICS-Hydro: All we need to do is provide the information, and we will write the text files as required.\n",
    "\n",
    "In the next cell, we will provide the forcing data. This can be precipitation, max and min temperatures, evapotranspiration, rainfall, snowfall, and other variables that could be used by your Raven model. Note that forcing data can also include observed streamflow if you also want to compute an objective function, or as we will see in the tutorial notebook 06, for model calibration. Forcing data must be a path to one or multiple files. Here we will pass the three meteorological input files generated in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of forcing data files. You can add the files you need! As long as there are timestamps\n",
    "# associated with each value in the netcdf files, the code will accept them and use what it needs.\n",
    "forcing = (\"ERA5_tmax.nc\", \"ERA5_tmin.nc\", \"ERA5_pr.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step, we will define the hydrological response unit (HRU). For lumped models, there is only one unit so the following structure should be good. However, for distributed modelling, there will be more than one HRU, so we would use another tool to help us build the HRUs in that case. The HRU provides information on the area, elevation, and location of the catchment. \n",
    "\n",
    "For now, let's provide the basin properties such that Raven can run. These are the minimal values that must always be provided, but some models might require other inputs. Please see the documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hydrological response unit. We can use the information from the tutorial notebook #02! Here we are using\n",
    "# arbitrary data for a test catchment.\n",
    "hru = GR4JCN.LandHRU(\n",
    "    area=4250.6, elevation=843.0, latitude=54.4848, longitude=-123.3659\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next required inputs are the start and end dates for the simulation. The `start_date` and `end_date` arguments indicate when a simulation should start and end. As long as the forcing data covers the simulation period, it should work. If these parameters are not defined, then start and end dates default to the start and end of the driving data. \n",
    "\n",
    "To keep things simple, we will use a short 5-year period. Note that the dates are python datetime.datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "start_date = dt.datetime(1985, 1, 1)\n",
    "end_date = dt.datetime(1990, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we also need to provide some parameters to our model. We could calibrate them, but let's start by using some arbitrary parameters just to get the model to run. A more detailed overview is given towards the end of this notebook, but for now, you can get a glimpse of the required parameters by using the \"help\" command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(GR4JCN.Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the first lines that there are 6 parameters for GR4JCN, from GR4J_X1 to GR4J_X4, and two CEMANEIGE_X1(X2) parameters. Let's create a list with those parameters in order for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (3.9, 1.396, 200.29, 10.072, 16.9, 0.947)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we launch the model using all of the configurations as specified. We simply call the \"model\" object we created earlier, and pass the required inputs. You might see some warning messages, these are for information only and can be disregarded (usually, but check to make sure this is not impacting your simulations in an unexpected way!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model by passing the configuration variables we just established.\n",
    "model(\n",
    "    ts=forcing,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    hrus=(\n",
    "        hru,\n",
    "    ),  # Careful how this must be passed! This is due to the capability of running in distributed mode as well.\n",
    "    params=params,\n",
    "    run_name=\"test_basin\",  # OPTIONAL: You can give your run a specific name to identify the results more easily. Files will contain the run_name as a prefix.\n",
    "    overwrite=True,  # OPTIONAL: We can do this to overwrite old files with the new ones generated in this run (output files, etc.)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now explore the model outputs that have been generated, by using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model output choices\n",
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the reference corrected data into netCDF file. We will then apply a special code to remove a dimension in the dataset to make it applicable to the RAVEN models.\n",
    "import xarray as xr\n",
    "\n",
    "ds1 = xr.open_dataset(\"ERA5_tmax.nc\")\n",
    "ds2 = xr.open_dataset(\"ERA5_tmin.nc\")\n",
    "ds3 = xr.open_dataset(\"ERA5_pr.nc\")\n",
    "\n",
    "ds4 = xr.merge([ds1, ds2, ds3])\n",
    "\n",
    "ds4.to_netcdf(\"ERA5_weather_data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 3654)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1980-12-31 1981-01-01 ... 1991-01-01\n",
      "Data variables:\n",
      "    tmax     (time) float32 ...\n",
      "    tmin     (time) float32 ...\n",
      "    pr       (time) float32 ...\n",
      "Attributes:\n",
      "    long_name:       2 metre temperature\n",
      "    nameCDM:         2_metre_temperature_surface\n",
      "    nameECMWF:       2 metre temperature\n",
      "    product_type:    analysis\n",
      "    shortNameECMWF:  2t\n",
      "    standard_name:   air_temperature\n",
      "    units:           degC\n",
      "    grid_mapping:    crs\n"
     ]
    }
   ],
   "source": [
    "print(ds4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "from ravenpy.new_config import commands as rc\n",
    "from ravenpy.new_config.emulators import GR4JCN\n",
    "\n",
    "hru = {}\n",
    "hru = dict(\n",
    "    area=4250.6,\n",
    "    elevation=843.0,\n",
    "    latitude=54.4848,\n",
    "    longitude=-123.3659,\n",
    "    hru_type=\"land\",\n",
    ")\n",
    "\n",
    "data_type = [\"TEMP_MAX\", \"TEMP_MIN\", \"PRECIP\"]\n",
    "\n",
    "alt_names = {\n",
    "    \"RAINFALL\": \"rain\",\n",
    "    \"TEMP_MIN\": \"tasmin\",\n",
    "    \"TEMP_MAX\": \"tasmax\",\n",
    "    \"PET\": \"pet\",\n",
    "    \"HYDROGRAPH\": \"qobs\",\n",
    "    \"SNOWFALL\": \"snow\",\n",
    "    \"PRECIP\": \"pr\",\n",
    "}\n",
    "\n",
    "m = GR4JCN(\n",
    "    params=[0.529, -3.396, 407.29, 1.072, 16.9, 0.947],\n",
    "    Gauge=rc.Gauge.from_nc(\n",
    "        \"ERA5_weather_data.nc\",\n",
    "        data_type=data_type,\n",
    "        alt_names=alt_names,\n",
    "        extra={\n",
    "            1: {\"elevation\": hru[\"elevation\"], \"latitude\": 45.00, \"longitude\": -123.00}\n",
    "        },\n",
    "    ),\n",
    "    HRUs=[hru],\n",
    "    StartDate=dt.datetime(1985, 1, 1),\n",
    "    EndDate=dt.datetime(1987, 1, 1),\n",
    "    RunName=\"test\",\n",
    "    CustomOutput=rc.CustomOutput(\"YEARLY\", \"AVERAGE\", \"PRECIP\", \"ENTIRE_WATERSHED\"),\n",
    "    GlobalParameter={\"AVG_ANNUAL_RUNOFF\": 208.480},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GR4JCN' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m m\u001b[38;5;241m.\u001b[39mbuild(workdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ets/src/run_results2\u001b[39m\u001b[38;5;124m\"\u001b[39m, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GR4JCN' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "m.build(workdir=\"/home/ets/src/run_results2\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are as follow:\n",
    "\n",
    "- hydrograph: The actual simulated hydrograph (q_sim), in netcdf format. It also contains the observed discharge (q_obs) if observed streamflow was provided as a forcing file.\n",
    "- storage: The state variables of the simulation duration, in netcdf format\n",
    "- solution: The state variables at the end of the simulation, which are saved as a \".rvc\" file that can be used to hot-start a model (for forecasting, for example)\n",
    "- rv_config: The model and data files packaged into a zip file that can be downloaded to run this exact model setup elsewhere on PAVICS-Hydro or on your local machine.\n",
    "\n",
    "You can explore the outputs using one of the following two syntaxes. One provides a path to the data, one actually loads the data into memory to be used directly in another cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This syntax will allow you to get the path to where the output files are located on the server.\n",
    "print(model.outputs[\"hydrograph\"])\n",
    "print(model.outputs[\"storage\"])\n",
    "print(model.outputs[\"solution\"])\n",
    "print(model.outputs[\"rv_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model outputs are actually already loaded as Python objects in memory, thus we can access the data directly.\n",
    "# Note that there is no way to work with the zip-file directly, so only the objects that contain useful data can be read-in this way:\n",
    "print(\"----------------HYDROGRAPH----------------\")\n",
    "print(model.hydrograph)\n",
    "print(\"\")\n",
    "print(\"-----------------STORAGE------------------\")\n",
    "print(model.storage)\n",
    "print(\"\")\n",
    "print(\"-----------------SOLUTION-----------------\")\n",
    "print(model.solution)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model has generated a simulation using the forcing data we provided, but it only used the period between the start_date and end_date. We can confirm this by looking at the forcing data. Since we have 3 forcing data files, we will want to open them using the 'open_mfdataset' method in xarray:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "dataset = xr.open_mfdataset(forcing)\n",
    "print(dataset)\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dates cover the period 1980-01-01 to 1991-01-01. In our simulation, we only ask to run over the period from 1985-01-01 to 1991-01-01. Raven takes care of subsetting the data for the required period. We can look at the simulated streamflow from Raven to confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the graphing utility built to handle Raven model outputs\n",
    "from ravenpy.utilities.nb_graphs import hydrographs\n",
    "\n",
    "hydrograph_objects = model.hydrograph\n",
    "hydrographs(hydrograph_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the simulated flow covers only the period we asked for. The results probably don't look good, but that's OK! We will soon calibrate our model to get reasonable parameters.\n",
    "\n",
    "We could also simply do basic plots using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hydrograph.q_sim.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can inspect and work with other state variables in the model outputs. For example, say we want to investigate the snow water equivalent timeseries. We can first get the list of available state variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.storage.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then plot the variable of interest:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the \"Snow\" variable\n",
    "model.storage[\"Snow\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, PAVICS-Hydro makes it easy to build a hydrological model, run it with forcing data, and then interact with the results! In the next notebooks, we will see how to use model configuration files (the .rvX files) to setup and run a model, and also how to calibrate its parameters. \n",
    "\n",
    "\n",
    "\n",
    "## Supplementary information on Hydrological response unit definition\n",
    "Raven requires a description of the watershed streamflow is simulated in. Different models require different parameters, but minimally, area, elevation, latitude and longitude are required. These data need to be provided for a few reasons:\n",
    "* Area is required since the size of the watershed will directly influence the simulated streamflow. Units are in square kilometers (km²).\n",
    "* Elevation (average elevation of the watershed) is required, although in many models the value is not actually used and therefore can be set to an arbitrary number. We strongly recommend using the real elevation as that will ensure that the value is present if you decide to switch to another model that requires elevation. Elevation is expressed in meters above mean sea level.\n",
    "* Latitude and longitude refer to the catchment centroid, and are used, among others, for evapotranspiration  computations. They are expressed in decimal degrees (°), with longitudes within [-180, 180].\n",
    "\n",
    "These values should be either precomputed externally, or they can be computed using the PAVICS-Hydro geophysical extraction toolbox that we used in the second tutorial notebook.\n",
    "\n",
    "## Supplementary information on model parameters\n",
    "\n",
    "Each model requires a set of tuning parameters to represent and compensate for unknown quantities in certain hydrological processes. Some models have more parameters than others, for example:\n",
    "\n",
    "* GR4JCN = 6 parameters\n",
    "* HMETS = 21 parameters\n",
    "* MOHYSE = 10 parameters\n",
    "* HBVEC = 21 parameters\n",
    "\n",
    "These parameters are found through calibration by tuning their values until the simulated streamflow matches the observations as much as possible. PAVICS-Hydro provides an integrated calibration toolbox that will be explored in the the 6th step of this tutorial. For now, we simply provided a set of parameters but it is not yet fully calibrated. This explains the poor quality of the simulated hydrograph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore!\n",
    "With this information in mind, you can now explore running different models and parameters and on different periods, and display the simulated hydrographs. You can change the start and end dates, the area, latitude, and even add other options that you might find in the documentation or in later tutorials.\n",
    "\n",
    "If you want to run other models than GR4JCN, you can use these parameter sets:\n",
    "\n",
    "#### HMETS: \n",
    "params = (9.5019, 0.2774, 6.3942, 0.6884, 1.2875, 5.4134, 2.3641, 0.0973, 0.0464, 0.1998, 0.0222, -1.0919, 2.6851, 0.3740, \n",
    "          1.0000, 0.4739, 0.0114, 0.0243, 0.0069, 310.7211, 916.1947)\n",
    "       \n",
    "#### MOHYSE:\n",
    "params = (1.0, 0.0468, 4.2952, 2.658, 0.4038, 0.0621, 0.0273, 0.0453, 0.9039, 5.6167)\n",
    "\n",
    "#### HBVEC:\n",
    "params = (0.059845, 4.07223, 2.00157, 0.034737, 0.09985, 0.506, 3.4385, 38.32455, 0.46066, 0.06304, 2.2778, 4.8737,\n",
    "          0.5718813, 0.04505643, 0.877607, 18.94145, 2.036937, 0.4452843, 0.6771759, 1.141608, 1.024278)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
