{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Emulating hydrological models\n",
    "\n",
    "## Using Ravenpy to emulate an existing hydrological model\n",
    "\n",
    "In this notebook, we will demonstrate the versatility of the Raven modelling framework to emulate one of eight hydrological models that are currently supported. We will walk through the different configuration parameters required to build the model and simulate streamflow on a catchments. We will also show how to import files from a pre-configured Raven configuration that users can inport into Ravenpy instead of using one of the default emulators.\n",
    "\n",
    "## A note on datasets\n",
    "\n",
    "There are numerous ways to run a Raven model and to pass its required input data. For this introduction to RavenPy, we will use our ERA5 data we generated in the previous notebook and we will configure the Raven model instance on the fly! In the next tutorials, we will see how users can import and use their own datasets to make the entire process flexible and tailored to the user needs.\n",
    "\n",
    "## Using templated model emulators\n",
    "The first thing we need to run the raven model is... a Raven model! Raven is not a model per se, but a modelling framework that can be used to build hydrological models from their underlying components. For now, PAVICS-Hydro allows building a set of pre-determined models. The Python wrapper offers at present eight model emulators: GR4J-CN, HMETS, MOHYSE, HBV-EC, Canadian Shield, HYPR, Sacramento and Blended. For each of these, templated configuration files are available to facilitate launching the model with options passed by Python at run-time.\n",
    "\n",
    "In the next cell, we are going to import the possible models, and later, we will configure and run the GR4J-CN model. Please see the documentation for more details on the mandatory vs optional parameters, and what they represent. A small glimpse is provided here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the list of possible model templates.\n",
    "from ravenpy.new_config.emulators import (\n",
    "    GR4JCN,\n",
    "    HBVEC,\n",
    "    HMETS,\n",
    "    HYPR,\n",
    "    SACSMA,\n",
    "    Blended,\n",
    "    CanadianShield,\n",
    "    Mohyse,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# Import other required packages:\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "from ravenpy.new_config import commands as rc\n",
    "from ravenpy.utilities.testdata import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step, we will define the hydrological response unit (HRU). For lumped models, there is only one unit so the following structure should be good. However, for distributed modelling, there will be more than one HRU, so we would use another tool to help us build the HRUs in that case. The HRU provides information on the area, elevation, and location of the catchment.\n",
    "\n",
    "For now, let's provide the basin properties such that Raven can run. These are the minimal values that must always be provided, but some models might require other inputs. Please see the Raven documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hydrological response unit. We can use the information from the tutorial notebook #02! Here we are using\n",
    "# arbitrary data for a test catchment.\n",
    "hru = {}\n",
    "hru = dict(\n",
    "    area=4250.6,\n",
    "    elevation=843.0,\n",
    "    latitude=54.4848,\n",
    "    longitude=-123.3659,\n",
    "    hru_type=\"land\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next required inputs are the start and end dates for the simulation. The `start_date` and `end_date` arguments indicate when a simulation should start and end. As long as the forcing data covers the simulation period, it should work. If these parameters are not defined, then start and end dates default to the start and end of the driving data.\n",
    "\n",
    "To keep things simple, we will use a short 5-year period. Note that the dates are python datetime.datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime(1985, 1, 1)\n",
    "end_date = dt.datetime(1990, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to build our first Raven-based hydrological model. the model will be the GR4JCN model. The following code block will show and describe every step. However, more control options are available for users. Please see the documentation for a more detailed explanation on model options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ets/src/RavenPy/ravenpy/utilities/testdata.py:131: UserWarning: notebook_inputs/ERA5_tmax.nc.md5 not accessible online. Unable to determine validity with upstream repo.\n",
      "  warnings.warn(msg)\n",
      "/home/ets/src/RavenPy/ravenpy/utilities/testdata.py:131: UserWarning: notebook_inputs/ERA5_tmin.nc.md5 not accessible online. Unable to determine validity with upstream repo.\n",
      "  warnings.warn(msg)\n",
      "/home/ets/src/RavenPy/ravenpy/utilities/testdata.py:131: UserWarning: notebook_inputs/ERA5_pr.nc.md5 not accessible online. Unable to determine validity with upstream repo.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rvi': PosixPath('/tmp/NB4d1mhun7o/test_NB_04.rvi'),\n",
       " 'rvp': PosixPath('/tmp/NB4d1mhun7o/test_NB_04.rvp'),\n",
       " 'rvc': PosixPath('/tmp/NB4d1mhun7o/test_NB_04.rvc'),\n",
       " 'rvh': PosixPath('/tmp/NB4d1mhun7o/test_NB_04.rvh'),\n",
       " 'rvt': PosixPath('/tmp/NB4d1mhun7o/test_NB_04.rvt')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required packages. We already imported the GR4JCN emulator in the first cell, but let's keep it here for\n",
    "# completeness.\n",
    "from ravenpy.new_config.emulators import GR4JCN\n",
    "\n",
    "# Alternative variable names are useful for allowing Raven to read variables from NetCDF files even if the variable\n",
    "# names are not those that are expected by Raven. For example, our ERA5-dernived temperature variables are named\n",
    "# \"tmax\" and \"tmin\", whereas Raven expects \"TEMP_MAX\" and \"TEMP_MIN\". Therefore, instead of forcing users to rename\n",
    "# their variables, we provide a mechanism to tell Raven which variables in the NetCDF files correspond to which\n",
    "# meteorological variable.\n",
    "alt_names = {\n",
    "    \"TEMP_MIN\": \"tmin\",\n",
    "    \"TEMP_MAX\": \"tmax\",\n",
    "    \"PRECIP\": \"pr\",\n",
    "}\n",
    "\n",
    "# Here is where we build the raven configuration. We will first configure the model in memory based on the user\n",
    "# preferences, and then we will write the Raven configuration files to disk such that Raven can read them and\n",
    "# execute a simulation. In this case, we are building a GR4JCN model, but you could change this to any of the\n",
    "# eight models that are preconfigured for direct emulation in Ravenpy.\n",
    "\n",
    "data_kwds = {\n",
    "    \"ALL\": {\n",
    "        \"elevation\": hru[\"elevation\"],\n",
    "        \"latitude\": hru[\"latitude\"],\n",
    "        \"longitude\": hru[\"longitude\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get the weather data. It can either be to a data file that was already in the same folder/workspace as this\n",
    "# notebook, as we generated in the previous notebook, or it could be a path to a file stored elsewhere.\n",
    "\n",
    "# Example for using the data we just generated in Notebook 03:\n",
    "\"\"\"\n",
    "ERA5_tmax = \"ERA5_tmax.nc\"\n",
    "ERA5_tmin = \"ERA5_tmin.nc\"\n",
    "ERA5_pr = \"ERA5_pr.nc\"\n",
    "\"\"\"\n",
    "\n",
    "# In our case, we will prefer to link to existing, pre-computed and locally stored files to keep things tidy:\n",
    "ERA5_tmax = get_file(\"notebook_inputs/ERA5_tmax.nc\")\n",
    "ERA5_tmin = get_file(\"notebook_inputs/ERA5_tmin.nc\")\n",
    "ERA5_pr = get_file(\"notebook_inputs/ERA5_pr.nc\")\n",
    "\n",
    "\n",
    "m = GR4JCN(\n",
    "    # Raven requires parameters for the GR4JCN model. For now, we provide default values, but in a later notebook\n",
    "    # we will show how to calibrate and find new parameters for our model.\n",
    "    params=[0.529, -3.396, 407.29, 1.072, 16.9, 0.947],\n",
    "    # Here we will prepare the weather gauge data to be fed to the model. The data could also come from other\n",
    "    # sources such as the ERA5 reanalysis product. There are 2 ways to do this. We will show one way here, and\n",
    "    # then show the alternative method in the following cell.\n",
    "    #\n",
    "    # METHOD 1: If you have one netcdf file of data per meteorological variable (such as what is generated in the\n",
    "    #    03_Extracting_forcing_data.ipynb notebook), you can add them successively as follows. Note that we are\n",
    "    #    creating a gauge for each variable. Raven will use the data from the three sources to provide forcing\n",
    "    #    data to the simulation.\n",
    "    #\n",
    "    #   You can add the files you need! As long as there are timestamps associated with each value in the netcdf\n",
    "    #   files, and the other required information (data_type, alt_names, other required information), the code\n",
    "    #   will accept them and use what it needs. As per the Raven model itself, the gauge station elevation, latitude\n",
    "    #   and longitude are required to let the model run. For lumped models such as the ones we are currently\n",
    "    #   emulating, there is only one \"station\" that corresponds to the basin-averaged weahter. In this case, we\n",
    "    #   set the station elevation to that of the mean catchment elevation to remove any adiabatic gradient\n",
    "    #   modifications to the data. We also provide the catchment centroid latitude and longitude which we take\n",
    "    #   from the only HRU defining the entire catchment. For multi-gauge basins and semi-distributed models, the\n",
    "    #   latitude and longitude must be correctly identified for each station.\n",
    "    Gauge=[\n",
    "        rc.Gauge.from_nc(\n",
    "            ERA5_tmax,  # This is a path to the file of ERA5-derived maximum daily temperature.\n",
    "            data_type=[\n",
    "                \"TEMP_MAX\"\n",
    "            ],  # Raven expects maximum temperature to be identified as \"TEMP_MAX\", so we indicate that this variable is maximum temperature.\n",
    "            alt_names=alt_names,  # However, the variable name in the file is different to the one Raven expects: use alt-names.\n",
    "            data_kwds=data_kwds,\n",
    "        ),\n",
    "        rc.Gauge.from_nc(\n",
    "            ERA5_tmin,\n",
    "            data_type=[\"TEMP_MIN\"],\n",
    "            alt_names=alt_names,\n",
    "            data_kwds=data_kwds,\n",
    "        ),\n",
    "        rc.Gauge.from_nc(\n",
    "            ERA5_pr, data_type=[\"PRECIP\"], alt_names=alt_names, data_kwds=data_kwds\n",
    "        ),\n",
    "    ],\n",
    "    # The HRU as defined earlier must be provided. This is the physical representation of the catchment that Raven\n",
    "    # needs for certain models and processes.\n",
    "    HRUs=[hru],\n",
    "    # Model simulation start and end dates.\n",
    "    StartDate=start_date,\n",
    "    EndDate=end_date,\n",
    "    # Name of the simulation. Raven will prefix all .rvX files and model outputs with the runName.\n",
    "    RunName=\"test_NB_04\",\n",
    "    # Custom outputs allow pre-processing of certain statistics and variables after the model runs. Please see the\n",
    "    # documentation for more details on possible options.\n",
    "    CustomOutput=rc.CustomOutput(\"YEARLY\", \"AVERAGE\", \"PRECIP\", \"ENTIRE_WATERSHED\"),\n",
    "    # GR4JCN needs an extra constant parameter for the catchment, corresponding to the G50 parameter in the CEMANEIGE\n",
    "    # description. Here is how we provide it.\n",
    "    GlobalParameter={\"AVG_ANNUAL_RUNOFF\": 208.480},\n",
    ")\n",
    "\n",
    "# We are now ready to write this newly-configured model to disk through the use of .rvX files that Raven will read.\n",
    "\n",
    "# In the following code snippet, there is a \"workdir\" path that must be provided. This indicates the path\n",
    "# where the data used to run the model (RAVEN .RV files) will be made available from the PAVICS Jupyter environment.\n",
    "# The default \"workdir\" setting puts model outputs in the temporary directory (\"/tmp\"),\n",
    "# which is not visible from the Jupyter file explorer. Therefore, You can change the last subfolder,\n",
    "# but '/notebook_dir/writable-workspace/' must be the beginning  of the path when running on the PAVICS platform.\n",
    "\n",
    "workdir = Path(tempfile.mkdtemp(prefix=\"NB4\"))\n",
    "m.write_rv(workdir=workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ets/src/RavenPy/ravenpy/utilities/testdata.py:131: UserWarning: notebook_inputs/ERA5_weather_data.nc.md5 not accessible online. Unable to determine validity with upstream repo.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rvi': PosixPath('/tmp/NB4d1mhun7o/test_NB04_b.rvi'),\n",
       " 'rvp': PosixPath('/tmp/NB4d1mhun7o/test_NB04_b.rvp'),\n",
       " 'rvc': PosixPath('/tmp/NB4d1mhun7o/test_NB04_b.rvc'),\n",
       " 'rvh': PosixPath('/tmp/NB4d1mhun7o/test_NB04_b.rvh'),\n",
       " 'rvt': PosixPath('/tmp/NB4d1mhun7o/test_NB04_b.rvt')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2- Alternatively, we could already have (or we could create) a single netcdf file containing all the required\n",
    "#    forcing data. Since we computed such a merged file in Notebook 03, let's reuse it here\n",
    "\n",
    "# Example for using the data we just generated in Notebook 03:\n",
    "\"\"\"\n",
    "ERA5_full = ERA5_weather_data.nc\n",
    "\"\"\"\n",
    "\n",
    "# In our case, we will prefer to link to existing, pre-computed and locally stored files to keep things tidy:\n",
    "ERA5_full = get_file(\"notebook_inputs/ERA5_weather_data.nc\")\n",
    "\n",
    "#    Since our meteorological gauge data is all included in a single file, we need to tell the model which variables\n",
    "#    we are providing. We will generate the list now and pass it later to Ravenpy as an argument to the model.\n",
    "data_type = [\"TEMP_MAX\", \"TEMP_MIN\", \"PRECIP\"]\n",
    "\n",
    "#    Now that we have the single file containing tmax, tmin and pr, we can setup a single gauge that contains all three.\n",
    "m = GR4JCN(\n",
    "    params=[0.529, -3.396, 407.29, 1.072, 16.9, 0.947],\n",
    "    # Setup the gauge using the second method, i.e., using a single file that contains all meteorological inputs. As\n",
    "    # you can see, a single gauge is added, but it contains all the information we need.\n",
    "    Gauge=[\n",
    "        rc.Gauge.from_nc(\n",
    "            ERA5_full,  # Path to the ERA5 file containing all three meteorological variables\n",
    "            data_type=data_type,  # Note that this is the list of all the variables\n",
    "            alt_names=alt_names,  # Note that all variables here are mapped to their names in the netcdf file.\n",
    "            data_kwds=data_kwds,\n",
    "        )\n",
    "    ],\n",
    "    HRUs=[hru],\n",
    "    StartDate=start_date,\n",
    "    EndDate=end_date,\n",
    "    RunName=\"test_NB04_b\",\n",
    "    CustomOutput=rc.CustomOutput(\"YEARLY\", \"AVERAGE\", \"PRECIP\", \"ENTIRE_WATERSHED\"),\n",
    "    GlobalParameter={\"AVG_ANNUAL_RUNOFF\": 208.480},\n",
    ")\n",
    "\n",
    "# Now we will write the files to disk to prepare them for Raven. This step is not strictly necessary since the\n",
    "# next step will also write files to disk automatically. We will leave it here so we can see the intermediate step\n",
    "# and inspect the files if necessary.\n",
    "\n",
    "m.write_rv(workdir=workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that both methods generated .rvX files in the indicated path. This makes the Ravenpy platform more flexible for various use-cases, where some data can be stored in independent files or databases (perhaps temperatures come from one source and precipitation from another source).\n",
    "\n",
    "The above code only created the .rvX files. The model did not actually run yet. To do so, we must ask it to, as follows. Don't worry about the warnings: Raven is informing us that it has generated some internal parameters to build the model configuration based on some of the parameters we provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RavenError",
     "evalue": "Config directory: /tmp/NB4d1mhun7o\nCannot find or read .rvi file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRavenError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m configdir \u001b[38;5;241m=\u001b[39m workdir\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Run the model and get the path to the outputs folder that can be used in the output reader.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m outputs_path \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfigdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get the outputs using the Output Reader object.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m OutputReader(run_name\u001b[38;5;241m=\u001b[39mrun_name, path\u001b[38;5;241m=\u001b[39moutputs_path)\n",
      "File \u001b[0;32m~/src/RavenPy/ravenpy/ravenpy.py:292\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(modelname, configdir, outputdir, overwrite)\u001b[0m\n\u001b[1;32m    289\u001b[0m     warn(msg, category\u001b[38;5;241m=\u001b[39mRavenWarning)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RavenError(\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfigdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m messages[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    294\u001b[0m     )\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputdir\n",
      "\u001b[0;31mRavenError\u001b[0m: Config directory: /tmp/NB4d1mhun7o\nCannot find or read .rvi file"
     ]
    }
   ],
   "source": [
    "# If we want to import our own raven configuration files and forcing data, we can do so by importing them\n",
    "# using the ravenpy.run  method. This will run the model exactly as the users will have designed it.\n",
    "from ravenpy import OutputReader\n",
    "from ravenpy.ravenpy import run\n",
    "\n",
    "# This is used to specify the raven configuration files prefixes. In this case, files are named test_2.rvi, etc.\n",
    "run_name = \"test_2\"\n",
    "\n",
    "# This is the path where the files were uploaded by the user. Model outputs will also be placed there in a\n",
    "# subfolder called \"outputs\"\n",
    "configdir = workdir\n",
    "\n",
    "# Run the model and get the path to the outputs folder that can be used in the output reader.\n",
    "outputs_path = run(modelname=run_name, configdir=configdir)\n",
    "\n",
    "# Get the outputs using the Output Reader object.\n",
    "outputs = OutputReader(run_name=run_name, path=outputs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we already have a model configuration that we built in-memory (such as the \"m\" GR4JCN model we built above),\n",
    "# then we can use the Emulator object to simply emulate the model we were working on and get outputs directly\n",
    "from ravenpy import Emulator\n",
    "\n",
    "# Prepare the emulator by writing files on disk\n",
    "e = Emulator(config=m)\n",
    "\n",
    "# Run the model and get the outputs.\n",
    "outputs = e.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the above demonstration shows how to use one of the eight emulators to run a Raven simulation. Ravenpy also contains other powerful tools to run other user-defined raven models by reading existing configuration files and running the model in Ravenpy. This means that users that already have Raven models of their systems can upload the configuration and hydrometeorological data netcdf files to their private account on the PAVICS-Hydro server and run their model there. Here is an example of how this could be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, no matter the method we used, we have the outputs of the model simulations in the \"outputs\" object. Let's explore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the files available in the outputs. Each of these can be accessed to get information about the simulation.\n",
    "outputs.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are as follow:\n",
    "\n",
    "- hydrograph: The actual simulated hydrograph (q_sim), in netcdf format. It also contains the observed discharge (q_obs) if observed streamflow was provided as a forcing file.\n",
    "- storage: The state variables of the simulation duration, in netcdf format\n",
    "- solution: The state variables at the end of the simulation, which are saved as a \".rvc\" file that can be used to hot-start a model (for forecasting, for example)\n",
    "- messages: A list of messages returned by Raven when executing the run.\n",
    "\n",
    "You can explore the outputs using othe following syntax. This loads the data into memory to be used directly in another cell for processing or analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model outputs are actually already loaded as Python objects in memory, thus we can access the data directly.\n",
    "print(\"----------------HYDROGRAPH----------------\")\n",
    "display(outputs.hydrograph)\n",
    "print(\"\")\n",
    "print(\"-----------------STORAGE------------------\")\n",
    "display(outputs.storage)\n",
    "print(\"\")\n",
    "print(\"-----------------SOLUTION-----------------\")\n",
    "display(outputs.solution)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the \"hydrograph\" section that the model has generated a simulation using the forcing data we provided, but it only used the period between the start_date and end_date we asked it for. We can see that the dates of the ERA5 data we requested in the previous notebook cover the period 1980-01-01 to 1991-01-01. In our simulation, we only ask to run over the period from 1985-01-01 to 1990-01-01. Raven takes care of subsetting the data for the required period. We can look at the simulated streamflow from Raven to confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the graphing utility built to handle Raven model outputs\n",
    "from ravenpy.utilities.nb_graphs import hydrographs\n",
    "\n",
    "hydrograph_objects = outputs.hydrograph\n",
    "hydrographs(hydrograph_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the simulated flow covers only the period we asked for. The results probably don't look good, but that's OK! We will soon calibrate our model to get reasonable parameters.\n",
    "\n",
    "We could also simply do basic plots using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.hydrograph.q_sim.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can inspect and work with other state variables in the model outputs. For example, say we want to investigate the snow water equivalent timeseries. We can first get the list of available state variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(outputs.storage.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then plot the variable of interest:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the \"Snow\" variable\n",
    "outputs.storage[\"Snow\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, PAVICS-Hydro makes it easy to build a hydrological model, run it with forcing data, and then interact with the results! In the next notebooks, we will see how to adjust configuration files (the .rvX files) to setup and run a model, and also how to calibrate its parameters.\n",
    "\n",
    "\n",
    "\n",
    "## Supplementary information on Hydrological response unit definition\n",
    "Raven requires a description of the watershed streamflow is simulated in. Different models require different parameters, but minimally, area, elevation, latitude and longitude are required. These data need to be provided for a few reasons:\n",
    "* Area is required since the size of the watershed will directly influence the simulated streamflow. Units are in square kilometers (km²).\n",
    "* Elevation (average elevation of the watershed) is required, although in many models the value is not actually used and therefore can be set to an arbitrary number. We strongly recommend using the real elevation as that will ensure that the value is present if you decide to switch to another model that requires elevation. Elevation is expressed in meters above mean sea level.\n",
    "* Latitude and longitude refer to the catchment centroid, and are used, among others, for evapotranspiration  computations. They are expressed in decimal degrees (°), with longitudes within [-180, 180].\n",
    "\n",
    "These values should be either precomputed externally, or they can be computed using the PAVICS-Hydro geophysical extraction toolbox that we used in the second tutorial notebook.\n",
    "\n",
    "## Supplementary information on model parameters\n",
    "\n",
    "Each model requires a set of tuning parameters to represent and compensate for unknown quantities in certain hydrological processes. Some models have more parameters than others, for example:\n",
    "\n",
    "* GR4JCN = 6 parameters\n",
    "* HMETS = 21 parameters\n",
    "* MOHYSE = 10 parameters\n",
    "* HBVEC = 21 parameters\n",
    "\n",
    "These parameters are found through calibration by tuning their values until the simulated streamflow matches the observations as much as possible. PAVICS-Hydro provides an integrated calibration toolbox that will be explored in the the 6th step of this tutorial. For now, we simply provided a set of parameters but it is not yet fully calibrated. This explains the poor quality of the simulated hydrograph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore!\n",
    "With this information in mind, you can now explore running different models and parameters and on different periods, and display the simulated hydrographs. You can change the start and end dates, the area, latitude, and even add other options that you might find in the documentation or in later tutorials.\n",
    "\n",
    "If you want to run other models than GR4JCN, you can use these parameter sets:\n",
    "\n",
    "#### HMETS:\n",
    "params = (9.5019, 0.2774, 6.3942, 0.6884, 1.2875, 5.4134, 2.3641, 0.0973, 0.0464, 0.1998, 0.0222, -1.0919, 2.6851, 0.3740,\n",
    "          1.0000, 0.4739, 0.0114, 0.0243, 0.0069, 310.7211, 916.1947)\n",
    "\n",
    "#### MOHYSE:\n",
    "params = (1.0, 0.0468, 4.2952, 2.658, 0.4038, 0.0621, 0.0273, 0.0453, 0.9039, 5.6167)\n",
    "\n",
    "#### HBVEC:\n",
    "params = (0.059845, 4.07223, 2.00157, 0.034737, 0.09985, 0.506, 3.4385, 38.32455, 0.46066, 0.06304, 2.2778, 4.8737,\n",
    "          0.5718813, 0.04505643, 0.877607, 18.94145, 2.036937, 0.4452843, 0.6771759, 1.141608, 1.024278)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
