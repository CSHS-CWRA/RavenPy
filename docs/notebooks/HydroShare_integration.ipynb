{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHsuQMMJyms4"
   },
   "source": [
    "# Accessing HydroShare content\n",
    "\n",
    "The following code snippets show examples for how to use the HydroShare Python Client for search and acquire data. See the [documentation](https://hydroshare.github.io/hsclient/) to explore further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZNOazcn9-23"
   },
   "source": [
    "## Authenticating with HydroShare\n",
    "\n",
    "Before you start interacting with resources in HydroShare you will need to authenticate. Just call `hsclient.Hydroshare()` to be prompted for your username and password. You may also pass your credentials programatically. For this public notebook, we use a token and client_id to authenticate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from hsclient import HydroShare, Token\n",
    "\n",
    "# Authentication method using username and password\n",
    "\"\"\"\n",
    "username = 'XXXXX'\n",
    "password = 'XXXXX'\n",
    "hs = HydroShare(username=username, password=password)\n",
    "\"\"\"\n",
    "\n",
    "client_id = os.environ.get(\"HYDROSHARE_AUTH_CLIENT_ID\", \"<your_client_id>\")\n",
    "access_token = os.environ.get(\"HYDROSHARE_AUTH_TOKEN\", \"<your_auth_token>\")\n",
    "\n",
    "token = Token(access_token=access_token, token_type=\"bearer\")\n",
    "hs = HydroShare(client_id=client_id, token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're authenticated, let's search for data from the 2017 Harvey flood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test harvey netcdf file :  75d17f265dba4c8396725cf98f652302\n",
      "RAPID: Archiving and Enabling Community Access to Data from Recent US Hurricanes :  564b6d73040142579ad3236e1aeb4712\n",
      "Hurricane Harvey 2017 Collection :  2836494ee75e43a9bfb647b37260e461\n",
      "USGS - Harvey Gaged Streamflow Timeseries :  51d1539bf6e94b15ac33f7631228118c\n",
      "Harvey Flood Data Collections :  12e69ee668124fdf833b29b5167e03c3\n",
      "NOAA NHC - Harvey 2017 Storm Track :  6168b9969c984b658952a896710b65ef\n",
      "USGS - Harvey High Water Marks :  615d426f70cc4346875c725b4b8fdc59\n",
      "Harvey Basemap Data Collections :  7661752c688a4f3ebcf58f8657773530\n",
      "Texas-Harvey Basemap - Addresses and Boundaries :  d2bab32e7c1d4d55b8cba7221e51b02d\n",
      "Preserving a Flood of Data: Hurricane Harvey 2017 Data Archive :  64f6af3dcea4475688cac0d6b4917d8d\n",
      "Hurricane Harvey Streamflow Preview Notebook :  4c089adbbad74aeda3932d8ff283b2b5\n",
      "Harvey Basemap - Hydrology Map Data :  adb14c9c073e4eee8be82fadb21a0a93\n",
      "Civil Air Patrol - Harvey Oblique Aerial Photos :  85c5f592e347452a84f552f17a9a05c1\n",
      "CDC Social Vulnerability Index 2014 :  c2df2a80b9d6490788704a24854f4879\n",
      "HUC 120200 :  a29b1b3c4889429bb23072c214e432e8\n",
      "Hurricane Harvey NWM Subsetting Exercise :  3db192783bcb4599bab36d43fc3413db\n",
      "NOAA NHC - Irma Storm Track - Best Track + Advisories :  aa5c9982a4694a19be2fa9299b78e5ca\n",
      "Hurricane Harvey 2017 Story Map :  8161a96a08474d12bba219852409be61\n",
      "Perspectives on research gaps from the differences amongst Hurricane Harvey, Irma and Maria :  7be94dcca60c428e81a6846e97122579\n",
      "Hurricane Harvey NWIS Data :  2f469f714ea541dc86b6578066e7815f\n",
      "Data for \"A Computationally Efficient and Physically Based Approach for Urban Flood Modeling Using a Flexible Spatiotemporal Structure\" :  e314ed52a83a46dd9e575304c299bd83\n",
      "Test for versioning published resource :  c4037062b89d4e989b66a60b6ef176e4\n",
      "Test Collection Inner :  c34cacb091074999aba351698eba3861\n",
      "FEMA - Harvey Damage Assessments and Claims :  a52d209d46eb42578be0a7472c48e2d5\n",
      "FEMA - Harvey Flood Depths Grid :  e8768f4cb4d5478a96d2b1cbd00d9e85\n",
      "ECMWF GloFAS - Harvey+Irma Flood Area Grids :  9ff2b9ad3eb74b06a5af8491c399ee57\n",
      "NOAA NWC - Harvey National Water Model Streamflow Forecasts :  35d4502200764c2985c24ae5c8836ab9\n",
      "Hurricane Harvey flood inundation simulation :  fae24734d6fc47be8bf0b54d6a175d86\n",
      "Coupling coastal and hydrologic models through BMI and Nextgen National Water Model Framework in low gradient coastal regions of Galveston Bay, Texas, USA Results :  379b4c8c663c460d87c246641dc5cea2\n",
      "IGUIDE Shapefile Testing Resource :  9d413b9d57824a79b8239a5f7c4fdf51\n"
     ]
    }
   ],
   "source": [
    "results = hs.search(subject=[\"Harvey\"])\n",
    "for r in results:\n",
    "    print(r.resource_title, \": \", r.resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HydroShare resources are identified uniquely by their `resource_id`. Here we use the ID for the `USGS - Harvey Gaged Streamflow Timeseries` to see which files are stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USGS_Gages_TxLaMsAr_shapefile/USGS_Gages_TxLaMsAr.dbf',\n",
       " 'USGS_Gages_TxLaMsAr_shapefile.zip',\n",
       " 'download_usgs_gage_height_inst.R',\n",
       " 'USGS_gage_discharge_timeseries.zip',\n",
       " 'USGS_Harvey_gages_TxLaMsAr.csv',\n",
       " 'README.md',\n",
       " 'USGS_Gages_TxLaMsAr_shapefile/USGS_Gages_TxLaMsAr.prj',\n",
       " 'USGS gage timeseries example.png',\n",
       " 'USGS-NWS gages in Harvey study area.png',\n",
       " 'USGS_Gages_TxLaMsAr_shapefile/USGS_Gages_TxLaMsAr.shp',\n",
       " 'USGS_Gages_TxLaMsAr_shapefile/USGS_Gages_TxLaMsAr.shx',\n",
       " 'USGS_Gages_TxLaMsAr_shapefile/USGS_Gages_TxLaMsAr.shp.xml',\n",
       " 'USGS_gage_height_timeseries.zip',\n",
       " 'README-USGS Gaged Streamflow Timeseries.pdf',\n",
       " 'USGS_Gages_TxLaMsAr_shapefile/USGS_Gages_TxLaMsAr.cpg',\n",
       " 'USGS_Gages_TxLaMsAr_shapefile/USGS_Gages_TxLaMsAr.sbx',\n",
       " 'USGS_Gages_TxLaMsAr_shapefile/USGS_Gages_TxLaMsAr.sbn',\n",
       " 'download_usgs_gage_discharge_inst.R']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = hs.resource(\"51d1539bf6e94b15ac33f7631228118c\", validate=False)\n",
    "res.files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply use the `file_download` method to save a copy locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/USGS_Harvey_gages_TxLaMsAr.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.file_download(\"USGS_Harvey_gages_TxLaMsAr.csv\", save_path=\"/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, the data are stored locally and can be integrated into workflows.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HS_RDF_Examples.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
